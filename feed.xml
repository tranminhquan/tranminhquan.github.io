<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://tranminhquan.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://tranminhquan.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-01-04T12:45:21+00:00</updated><id>https://tranminhquan.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Diffusion Models: Fundamentals - Part 1</title><link href="https://tranminhquan.github.io/blog/2024/diffusion-models/" rel="alternate" type="text/html" title="Diffusion Models: Fundamentals - Part 1"/><published>2024-01-02T00:00:00+00:00</published><updated>2024-01-02T00:00:00+00:00</updated><id>https://tranminhquan.github.io/blog/2024/diffusion-models</id><content type="html" xml:base="https://tranminhquan.github.io/blog/2024/diffusion-models/"><![CDATA[<p>Update history</p> <ul> <li>20.12.2023: Created</li> <li>02.01.2024: Update the math formulation</li> <li>03.01.2024: Update the model backbone</li> <li>04.01.2024: Update the implementation</li> </ul> <h2 id="what-is-diffusion-model">What is Diffusion Model</h2> <ul> <li>Motivation <ul> <li>From VAE: the same concept but gradually</li> <li>From GAN: the same concept that generate from noise</li> </ul> </li> <li>General concept <ul> <li>Markov Chain with 2 stages: forward and reverse</li> <li>Forward process</li> <li>Reverse process</li> </ul> </li> <li>Objective function <ul> <li>Learn to generate the image from noise</li> </ul> </li> <li>Compare <ul> <li>to GAN: more stable in training</li> <li>to VAE:</li> </ul> </li> </ul> <h3 id="general-concept">General concept</h3> <p>The general objective is to gradually adding noise to the original image unitl it completely becames noise, and then try to generate back to the original image from the existing noise. By learning this process, a diffusion model is expected to learn how to generate an image from a noise distribution by learning the denoising process.</p> <p>Diffusion model is a Markov Chain process with two stages: forward and reverse.</p> <ul> <li>Forward process: <ul> <li>In the forward process, the objective is to adding noise to the image within finite steps until it completely becomes noise</li> </ul> </li> <li>Reverse process: <ul> <li>In the reverse process, the model learns to denoise from a noise distribution and generate back the original image within finite steps</li> </ul> </li> <li>Objective function: <ul> <li>Similar to VAE, diffusion model optimizes the evidence lower bound (ELBO), which means we want to maximize the log-likelihood between the original image and the generated one.</li> </ul> </li> </ul> <h2 id="math-formulation">Math formulation</h2> <ul> <li>We denote the real data distribution as \(q(x)\)</li> <li>A data point (real image) is sampled as \(\mathbf{x}_0 \sim q(\mathbf{x})\)</li> <li>The Markov chains is defined as \(T\) finite steps</li> </ul> <h3 id="forward-process">Forward process</h3> <div class="l-body-outset"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/diffusion_models/forward_process-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/diffusion_models/forward_process-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/diffusion_models/forward_process-1400.webp"/> <img src="/assets/img/diffusion_models/forward_process.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <ul> <li>In the forward process, at timestep t, we have the noised image \(\mathbf{x}_t\) by adding noise from a distribution (normally Gaussian) to the previous image \(\mathbf{x}_{t-1}\), this process is denoted as \(q(\mathbf{x}_t \vert \mathbf{x}_{t-1})\)</li> </ul> <p>Formally,</p> \[\begin{equation} \label{eq:original_q_forward} q(\mathbf{x}_t | \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t \mathbf{I}) \end{equation}\] <p>where \(\beta_{t}\) is a paramter to control the level of noise at timestep \(t\), \(\{\beta_t \in (0,1)\}_{t=1}^{T}\).</p> <p>Thanks to the property of the Markov chain, we can create a tractable closed. Given \(\alpha_t = 1 - \beta_t\), \(\bar{\alpha_t} = \prod_{i=1}^{t} \alpha_i\), then</p> \[\begin{equation} \label{eq:closed_form} \begin{aligned} \mathbf{x}_t &amp;= \sqrt{\alpha_t} \mathbf{x}_{t-1} + \sqrt{1 - \alpha_t} \epsilon_{t-1} \\ &amp;= \sqrt{1 - \alpha_t \alpha_{t-1}} \mathbf{x}_{t-2} + \sqrt{1 - \alpha_t \alpha_{t-1}} \bar\epsilon_{t-2} \\ &amp;= \dots \\ &amp;= \sqrt{\bar\alpha_t} \mathbf{x}_0 + \sqrt{1 - \bar\alpha_t} \epsilon \end{aligned} \end{equation}\] <p>On the above equation \eqref{eq:closed_form}, we denote \(\epsilon_t \in \mathcal{N}(0, \mathbf{I})\). \(\bar\epsilon_{t}\) is a merged Gaussian distribution.</p> <p>From that, the closed form of forward process is defined as</p> \[\begin{equation} \label{eq:closed_form_forward} q(\mathbf{x}_t | \mathbf{x}_{0}) = \mathcal{N} \left( \mathbf{x}_t; \sqrt{\bar{\alpha}_t} \mathbf{x}_{0}, (1 - \bar{\alpha}_t) \mathbf{I} \right) \end{equation}\] <h3 id="reverse-process">Reverse process</h3> <ul> <li>Theoretically, the reverse process would be \(q(\mathbf{x}_{t-1} \vert \mathbf{x}_{t})\).</li> <li>However, to find out the above distribution, we need to figure out the wholte data distribution, which is impractical</li> <li>The alternative is the reparameterizatin trick, sample from mean and distribution of the previous distribution. The approximation is \(p_{\theta}(\mathbf{x}_{t-1} \vert \mathbf{x}_t)\).</li> <li>Because \(q(\mathbf{x}_{t-1} \vert \mathbf{x}_{t})\) is a Gaussian distribution, with a small \(\beta_t\), \(p_{\theta}(\mathbf{x}_{t-1} \vert \mathbf{x}_t)\). is also a Gaussian distribution, so we can sample using the above clarification.</li> </ul> <p>Formally, \(\begin{equation} p_{\theta}(\mathbf{x}_{t-1} \vert \mathbf{x}_t) = \mathcal{N} \left( \mathbf{x}_{t}; \mathbf{\mu}_{\theta}(\mathbf{x}_t, t), \mathbf{\sum}_{\theta}(\mathbf{x}_t, t) \right) \end{equation}\)</p> <div class="l-body-outset"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/diffusion_models/reverse_process-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/diffusion_models/reverse_process-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/diffusion_models/reverse_process-1400.webp"/> <img src="/assets/img/diffusion_models/reverse_process.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h3 id="objective-function">Objective function</h3> <p>We optimize the ELBO function on the negative log-likelihod function.</p> \[\begin{equation} \begin{aligned} \mathbb{E}[-\log p_{\theta}(\mathbf{x_0})] &amp;\leq \mathbb{E_q}[-\log \frac{p_{\theta}(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} \vert \mathbf{x}_0)}] \\ &amp;= \mathbb{E_q}[-\log p(\mathbf{x}_T) - \sum_{t \geq 1} \frac{ p_{\theta}(\mathbf{x}_{t-1} \vert \mathbf{x}_t)} {q(\mathbf{x}_{t} \vert \mathbf{x}_{t-1})} ] \\ &amp;=: L \end{aligned} \end{equation}\] <p>Derive the above function, we get</p> \[\begin{equation} \label{eq:original_loss} L := \mathbb{E_q} \left[ \underbrace{D_{KL} \left( q(\mathbf{x}_T \vert \mathbf{x}_0) \enspace \vert\vert \enspace p_{\theta}(\mathbf{x}_T) \right) _ {L_T}} _{L_T} + \underbrace{\sum\limits_{t \geq 1} D_{KL} \left( q(\mathbf{x}_{t-1} \vert \mathbf{x}_{t}, \mathbf{x}_{0}) \enspace \vert\vert \enspace p_{\theta}(\mathbf{x}_{t-1} \vert \mathbf{x}_{t}) \right) } _{L_{t-1}} - \underbrace{\log p_{\theta} (\mathbf{x}_0 \vert \mathbf{x}_1)} _{L_0} \right] \end{equation}\] <p>In the above training loss, we observer there are three parts:</p> <ul> <li>\(L_T\) is a constant, and can be ignored during the training since \(q\) has no learnable parameters and \(\mathbf{x}_t\) is a Gaussian noise</li> <li>\(L_0\) is a reconstruction term and is learned using a seperate decoder following \(\mathcal{N} \sim (\mathbf{x}_0; \mu_\theta(\mathbf{x}_1, 1), \Sigma_\theta (\mathbf{x}_1, 1) )\)</li> <li>\(L_{t-1}\) is a learnable parameters and we focus on how to learn this subloss function.</li> </ul> <p>In \(L_{t-1}\), the term \(q(\mathbf{x}_{t-1} \vert \mathbf{x}_{t}, \mathbf{x}_{0})\) has not been defined. In words, it means we wish to denoise the image from previous noisy one \(\mathbf{x}_{t}\) and it is also conditioned on the original image \(\mathbf{x}_0\). As a result,</p> \[\begin{equation} \label{eq:original_reverse} q(\mathbf{x}_{t-1} \vert \mathbf{x}_{t}, \mathbf{x}_{0}) \sim \mathcal{N}(\mathbf{x}_{t-1}, \tilde\mu_t(\mathbf{x}_{t}, \mathbf{x}_0), \tilde\beta_{t} \mathbf{I}) \end{equation}\] <p>with</p> \[\begin{equation} \tilde\beta_t = \frac{1- \bar\alpha_{t-1}}{1 - \bar\alpha_t} \cdot \beta_t \end{equation}\] <p>Using the Bayes rules, \(\tilde\mu_t(\mathbf{x}_t, \mathbf{x}_0)\) in Equation \eqref{eq:original_reverse} can be derived into</p> \[\begin{equation} \label{eq:original_mu_noise} \tilde\mu_t(\mathbf{x}_t, \mathbf{x}_0) = \frac{\sqrt{\bar\alpha_{t-1}} \beta_t}{1 - \bar\alpha_t} \mathbf{x}_0 + \frac{\sqrt\alpha_t (1 - \bar\alpha_{t-1})}{1 - \bar\alpha_t} \mathbf{x}_t \end{equation}\] <p>However, it still depends on two variables, \(\mathbf{x}_0\) and \(\mathbf{x}_t\), we want to transform it to only depends on one variable. Because we have a tractable closed-form of \(\mathbf{x}_0\) and \(\mathbf{x}_t\) and \(\epsilon_t \sim \mathcal{N}(0, \mathbf{I})\) in Equation \eqref{eq:closed_form}, the Equation \eqref{eq:original_mu_noise} becomes</p> \[\begin{equation} \label{eq:mu_noise} \tilde\mu_t(\mathbf{x}_t) = \frac{1}{\sqrt{\alpha_t}} ( \mathbf{x}_{t} - \frac{1 - \alpha_t}{\sqrt{1 - \bar\alpha_t}} \epsilon_t ) \end{equation}\] <p>Recall the \(p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t)\) derive formula in Equation \eqref{eq:original_loss}, we can have the same transformation with a learnable \(\epsilon_\theta(\mathbf{x}_t, t)\) for \(\mu_\theta(\mathbf{x}_t, t)\)</p> \[\begin{equation} \label{eq:mu_learnable_noise} \mu_\theta(\mathbf{x}_t, t) = \frac{1}{\sqrt{\alpha_t}} ( \mathbf{x}_{t} - \frac{1 - \alpha_t}{\sqrt{1 - \bar\alpha_t}} \epsilon_\theta(\mathbf{x}_t, t) ) \end{equation}\] <p>From the above equation, we observe that the generated \(\mathbf{x}_t\) depends only on a trainable variable, which is \(\epsilon_\theta(\mathbf{x}_t, t)\), at timestep \(t\). The problem turns out to predict the noise of the generated image for every step \(t\) in the denoising process. As a result, we define a neural network to predict \(\epsilon_\theta(\mathbf{x}_t, t)\)</p> <p>Applying \eqref{eq:mu_noise} and \eqref{eq:mu_learnable_noise} into the \(L_{t-1}\), now the objective is to minimize the difference between the current noise and the predicted noise</p> \[\begin{equation} \begin{aligned} L_{t} &amp;= \mathbb{E}_{\mathbf{x}_0, \epsilon} \left[ \frac{1}{2 || \Sigma_\theta (\mathbf{x}_t, t) ||_2^2} || \tilde\mu_t(\mathbf{x}_t, \mathbf{x}_0) - \mu_\theta(\mathbf{x}_t, t) ||^2 \right] \\ &amp;= \mathbb{E}_{\mathbf{x}_0, \epsilon} \left[ \frac{(1 - \alpha_t)^2}{2 \alpha_t (1 - \bar\alpha_t) || \Sigma_\theta ||_2^2} || \epsilon_t - \epsilon_\theta(\sqrt{\alpha_t} \mathbf{x}_0 + \sqrt{1 - \bar\alpha_t} \epsilon_t, t) ||^2 \right] \end{aligned} \end{equation}\] <p>By discarding the regulaization term, Ho et al. proposed with a simpler version <d-cite key="ho2020_denoising"></d-cite></p> \[\begin{equation} \label{eq:simple_loss_function} L_{t}^{\text{simple}} = \mathbb{E}_{\mathbf{x}_0, \epsilon} \left[ || \epsilon_t - \epsilon_\theta(\sqrt{\alpha_t} \mathbf{x}_0 + \sqrt{1 - \bar\alpha_t} \epsilon_t, t) ||^2 \right] \end{equation}\] <p>Since we ignore the other parts of the overall loss function and with the simple version, the final loss function is</p> \[\begin{equation} L_{\text{simple}} = L_{t}^{\text{simple}} + C \end{equation}\] <p>where \(C\) is a constant</p> <details><summary>Explanation for the impractical of \(q(\mathbf{x}_{t-1} \vert \mathbf{x}_{t})\)</summary> <p>TODO</p> </details> <details><summary>Explanation for the reparameterization trick</summary> <p>TODO</p> </details> <details><summary>Bayes rule to expand the \(q(\mathbf{x}_{t} \vert \mathbf{x}_{t-1}, \mathbf{x}_{0})\)</summary> <p>TODO</p> </details> <h2 id="overall-training-process">Overall training process</h2> <p>The process of developing diffusion model consitst of training and sampling.</p> <h3 id="training">Training</h3> <p>For each training step:</p> <ul> <li>Sample an original image from the dataset: \(\mathbf{x}_0 \sim q(\mathbf{x}_0)\)</li> <li>Sample range of timestep \(t\) in range (1, \(T\)), for example, sampling with a uniform: \(t \sim \text{Uniform}(\{1, \dots, T\})\)</li> <li>Sample noise: \(\epsilon \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\)</li> <li>Calculate the gradient folllowing the loss function: \(\Delta_\theta || \epsilon - \epsilon_\theta(\sqrt{\alpha_t} \mathbf{x}_0 + \sqrt{1 - \bar\alpha_t} \epsilon_t, t)||^2\)</li> </ul> <h3 id="sampling">Sampling</h3> <p>The sampling process is when we want to generate the image from the noise distribution.</p> <ul> <li>First, we generate the noise: \(\mathbf{x}_T \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\)</li> <li>For each timestep from \(T\) to \(1\) <ul> <li>Sample embedding from the noise distribution: \(\mathbf{z} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\)</li> <li>Calculate the denoising version at timestep $t-1$ using the reparameterization trick:</li> </ul> \[\mathbf{x}_{t-1} \sim p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t) \\ \mathbf{x}_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_{t-1} - \frac{1 - \alpha_t}{\sqrt{1 - \bar\alpha_t} \epsilon_\theta(\mathbf{x}_t, t)} + \sigma_t \mathbf{z} \right)\] </li> <li>Get \(\mathbf{x}_0\)</li> </ul> <p>The two process are summarized as follow Algorithms</p> <div class="l-body-outset"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/diffusion_models/training_sampling_algorithms-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/diffusion_models/training_sampling_algorithms-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/diffusion_models/training_sampling_algorithms-1400.webp"/> <img src="/assets/img/diffusion_models/training_sampling_algorithms.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h2 id="model-backbone">Model backbone</h2> <p>Any model can be used as the backbone for a diffusion model. However, for the baseline Denoising Diffusion Probabilistic Model (DDPM), Ho et al. <d-cite key="ho2020_denoising"> propose to leverage U-Net as the backbone.</d-cite></p> <p>The advatange of U-Net architecture can be listed as follows:</p> <ul> <li>U-Net is a symetric architecture and is well-known for its application in segmentation. This means the architecture itself is potential for denoising tasks.</li> <li>The conventional structure of U-Net has encoder as the downsampling and decoder as the upsampling, with residual connection, which is similar to Auto-Encoder-based models.</li> <li>U-Net has many variants, the recent famous one is Attenion U-Net consisting of Wide Resnet blocks, Group Normalization, and Self-attention Blocks.</li> <li>However, to leverage the U-Net as the backbone, we need to differentiate between each timestep t. This can be resolved by using a Position Encoding. In <d-cite key="ho2020_denoising">, the authors use SinusoidalPositionEmbeddings.</d-cite></li> </ul> <div class="l-body-outset"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/diffusion_models/attention_unet-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/diffusion_models/attention_unet-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/diffusion_models/attention_unet-1400.webp"/> <img src="/assets/img/diffusion_models/attention_unet.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h2 id="summary">Summary</h2> <h2 id="implementation">Implementation</h2> <h3 id="training-process">Training process</h3> <p>Following the above algorithm</p> <ul> <li>Sample an original image from the dataset: \(\mathbf{x}_0 \sim q(\mathbf{x}_0)\).</li> <li>Sample range of timestep \(t\) in range \((1, T)\), for example, sampling with a uniform: \(t \sim \text{Uniform}(\{1, \dots, T\})\). In this step, we generate range of timestep with corresponding \(\beta_t\).</li> <li>Sample noise: \(\epsilon \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\). In this step, we sample noise and generate the noisy image at timestep \(t\) following Equation \eqref{eq:closed_form_forward}.</li> <li>Calculate the gradient folllowing the loss function: \(\Delta_\theta || \epsilon - \epsilon_\theta(\sqrt{\alpha_t} \mathbf{x}_0 + \sqrt{1 - \bar\alpha_t} \epsilon_t, t)||^2\). In this step, we calculate between the output of the model and the noisy image from the above step using Equation \eqref{eq:simple_loss_function}</li> </ul> <p>As a result, in summary, we will implement the process as follow:</p> <ul> <li>Timestep and corresponding beta scheduler given number of steps</li> <li>Sample a noisy image at a timestep \(t\) with Equation \eqref{eq:closed_form_forward}.</li> <li>Define the loss function to calculate Equation \eqref{eq:simple_loss_function}</li> </ul> <h4 id="timestep-and-beta-scheduler">Timestep and beta scheduler</h4> <p>The importance of forward process is to define how we generate number of finite timestep in range \((0, T)\). The original DDPM paper uses the linear schedule for simple.</p> <p>Recall Equation \eqref{eq:original_q_forward} with \(\beta_t\) as the parameter to control the level of noise. In the original implementation, the authors choose to scale linearly from \(\beta_1 = 10^{-4}\) to \(\beta_T = 0.02\). So we implement the same way.</p> <p>We define <code class="language-plaintext highlighter-rouge">linear_beta_schedule</code> as the linear timestep scheduler with an input as the number of timesteps <code class="language-plaintext highlighter-rouge">n_steps</code></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">linear_beta_schedule</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
    <span class="n">beta_start</span> <span class="o">=</span> <span class="mf">0.0001</span>
    <span class="n">beta_end</span> <span class="o">=</span> <span class="mf">0.02</span>
    
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">beta_start</span><span class="p">,</span> <span class="n">beta_end</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>
</code></pre></div></div> <p>We also need to prepare corresponding \(\alpha_t\) and \(\bar\alpha_t\). The following code prepare the list of <code class="language-plaintext highlighter-rouge">alpha</code> and utilization function to retrieve given timesteps</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># define alphas
</span><span class="n">alphas</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">betas</span>
<span class="n">cumprod_alphas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cumprod</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># bar_alpha
</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># util function to retrive data at timestep t
</span>
<span class="k">def</span> <span class="nf">extract</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">out_shape</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Extract from the list of data the t-element and reshape to the given_shape

    Args:
        data (list or tensor): input list of tensor of data to retrieve
        t (int): t element to retrieve data
        out_shape (tuple): output shape

    Returns:
        tensor: retrieved data with dedicated shape
    </span><span class="sh">"""</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">gather</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="p">.</span><span class="nf">cpu</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">out</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">*</span><span class="p">((</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">out_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))).</span><span class="nf">to</span><span class="p">(</span><span class="n">t</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div> <h4 id="sample-a-noisy-image-at-a-timestep">Sample a noisy image at a timestep</h4> <p>Recall the Equation \eqref{eq:closed_form_forward}</p> \[q(\mathbf{x}_t | \mathbf{x}_{0}) = \mathcal{N} \left( \mathbf{x}_t; \sqrt{\bar{\alpha}_t} \mathbf{x}_{0}, (1 - \bar{\alpha}_t) \mathbf{I} \right)\] <p>We implement a function to get noised image at any given timestep with given original image.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sample_noised_image</span><span class="p">(</span><span class="n">x_start</span><span class="p">,</span> <span class="n">timestep</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Sample a noised image at a timestep

    Args:
        x_start (tensor): x0, original image
        timestep (_type_): timestep t
        noise (_type_, optional): noise type. Defaults to None.
    </span><span class="sh">"""</span>
    
    <span class="k">if</span> <span class="n">noise</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x_start</span><span class="p">)</span>
    
    <span class="n">cumprod_alpha_t</span> <span class="o">=</span> <span class="nf">extract</span><span class="p">(</span><span class="n">cumprod_alphas</span><span class="p">,</span> <span class="n">timestep</span><span class="p">,</span> <span class="n">x_start</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    
    <span class="n">noised_t</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">cumprod_alpha_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_start</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">cumprod_alpha_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">noised_t</span>
    
</code></pre></div></div> <h4 id="define-the-transform-and-inverse-transform-process">Define the transform and inverse transform process</h4> <p>The transform process takes original image from PIL and transform to torch tensor data</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">image_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">transform</span> <span class="o">=</span> <span class="nc">Compose</span><span class="p">([</span>
    <span class="nc">Resize</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
    <span class="nc">CenterCrop</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
    <span class="nc">ToTensor</span><span class="p">(),</span> <span class="c1"># turn into torch Tensor of shape CHW, divide by 255
</span>    <span class="nc">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
    
<span class="p">])</span>
</code></pre></div></div> <p>The inverse transform process convert the tensor data back to the PIL image</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">reverse_transform</span> <span class="o">=</span> <span class="nc">Compose</span><span class="p">([</span>
     <span class="nc">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span>
     <span class="nc">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="p">.</span><span class="nf">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="c1"># CHW to HWC
</span>     <span class="nc">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span> <span class="o">*</span> <span class="mf">255.</span><span class="p">),</span>
     <span class="nc">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="p">.</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">)),</span>
     <span class="nc">ToPILImage</span><span class="p">(),</span>
<span class="p">])</span>
</code></pre></div></div> <h4 id="demo-the-forwarding-process">Demo the forwarding process</h4> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/demo_forwarding_diffusion_models.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <h4 id="define-the-loss-function">Define the loss function</h4> <p>From Equation \eqref{eq:simple_loss_function}, we can apply any conventional function such as L1, MSE, etc. to calculate the different between noised image at timestep \(t\) and the predicted noise from the model.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">denoise_model</span><span class="p">,</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">timestep</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">loss_type</span><span class="o">=</span><span class="sh">'</span><span class="s">mse</span><span class="sh">'</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">noise</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x_start</span><span class="p">)</span>
        
    <span class="n">x_noise</span> <span class="o">=</span> <span class="nf">sample_noised_image</span><span class="p">(</span><span class="n">x_start</span><span class="p">,</span> <span class="n">timestep</span><span class="p">,</span> <span class="n">noise</span><span class="p">)</span>
    <span class="n">predicted_noise</span> <span class="o">=</span> <span class="nf">denoise_model</span><span class="p">(</span><span class="n">x_start</span><span class="p">,</span> <span class="n">timestep</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">mse</span><span class="sh">'</span><span class="p">:</span>
        <span class="n">F</span><span class="p">.</span><span class="nf">mse_loss</span><span class="p">(</span><span class="n">x_noise</span><span class="p">,</span> <span class="n">predicted_noise</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="nc">NotImplementedError</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></div> <p>The above code takes <code class="language-plaintext highlighter-rouge">denoise_model</code> into account, which is neural network that we will implement. The model will predict the noise at timestep \(t\) given the original image. In the next section, we will implement the model as the Attention U-Net.</p> <h3 id="attention-u-net">Attention U-Net</h3> <p>There are modules we need to implement</p> <ul> <li>Positional Embeddings</li> <li>ResNet Block</li> <li>Attention Block</li> <li>Group Normalization</li> <li>Utils Blocks</li> </ul> <h4 id="positional-embeddings">Positional Embeddings</h4> <p>For each above timestep \(t\), we need to generate a positional embedding to differentiate between each timestep. The most common is to follow <d-cite key="vaswani2017_attention"> with Sinusodial Positional Embedding.</d-cite></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SinusodialPositionalEmbeddings</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">timestep</span><span class="p">):</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">timestep</span><span class="p">.</span><span class="n">device</span>
        <span class="n">half_dim</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">dim</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">half_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">half_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="n">embeddings</span><span class="p">)</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">timestep</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">embeddings</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">embeddings</span><span class="p">.</span><span class="nf">sin</span><span class="p">(),</span> <span class="n">embeddings</span><span class="p">.</span><span class="nf">cos</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">embeddings</span>
</code></pre></div></div> <h4 id="resnet-block">ResNet block</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Block</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">A unit block in ResNet module. Each block consists of a projection module, a group normalization, and an activation

    Args:
        nn (_type_): _description_
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">act_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">SiLU</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">GroupNorm</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">act_fn</span> <span class="o">=</span> <span class="nf">act_fn</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">scale_shift</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">scale_shift</span><span class="p">:</span>
            <span class="n">scale</span><span class="p">,</span> <span class="n">shift</span> <span class="o">=</span> <span class="n">scale_shift</span>
            <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="n">scale</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="n">shift</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">act_fn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ResNetBlock</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">time_emb_dim</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">act_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">SiLU</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
                <span class="nf">act_fn</span><span class="p">(),</span>
                <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">time_emb_dim</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">out_dim</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">time_emb_dim</span>
            <span class="k">else</span> <span class="bp">None</span>
        <span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">block1</span> <span class="o">=</span> <span class="nc">Block</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">act_fn</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">block2</span> <span class="o">=</span> <span class="nc">Block</span><span class="p">(</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">act_fn</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">res_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">in_dim</span> <span class="o">!=</span> <span class="n">out_dim</span> <span class="k">else</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Identity</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">time_emb</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">scale_shift</span> <span class="o">=</span> <span class="bp">None</span>
        
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">mlp</span> <span class="ow">and</span> <span class="n">time_emb</span><span class="p">:</span>
            <span class="n">time_emb</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">mlp</span><span class="p">(</span><span class="n">time_emb</span><span class="p">)</span>
            <span class="n">time_emb</span> <span class="o">=</span> <span class="nf">rearrange</span><span class="p">(</span><span class="n">time_emb</span><span class="p">,</span> <span class="sh">"</span><span class="s">b c -&gt; b c 1 1</span><span class="sh">"</span><span class="p">)</span>
            <span class="n">scale_shift</span> <span class="o">=</span> <span class="n">time_emb</span><span class="p">.</span><span class="nf">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            
        <span class="n">h</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">block1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scale_shift</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">block2</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        
        
        <span class="k">return</span> <span class="n">h</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="nf">res_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <h4 id="attention-block">Attention Block</h4> <p>We follow the implementation of the paper <d-cite key="vaswani2017_attention"></d-cite></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torch</span> <span class="kn">import</span> <span class="n">einsum</span>

<span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">head_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">head_dim</span> <span class="o">*</span> <span class="o">-</span><span class="mf">0.5</span>
        <span class="n">self</span><span class="p">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span>
        
        <span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">head_dim</span> <span class="o">*</span> <span class="n">heads</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">qkv_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
        
        <span class="n">qkv</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">qkv_proj</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="nf">chunk</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">t</span> <span class="p">:</span> <span class="nf">rearrange</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="sh">"</span><span class="s">b (h c) x y -&gt; b h c (x y)</span><span class="sh">"</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">heads</span><span class="p">),</span> <span class="n">qkv</span>
        <span class="p">)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">scale</span>
        
        <span class="n">sim</span> <span class="o">=</span> <span class="nf">einsum</span><span class="p">(</span><span class="sh">"</span><span class="s">b h d i, b h d j -&gt; b h i j</span><span class="sh">"</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
        <span class="n">sim</span> <span class="o">=</span> <span class="n">sim</span> <span class="o">-</span> <span class="n">sim</span><span class="p">.</span><span class="nf">amax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="nf">detach</span><span class="p">()</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="n">sim</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">out</span> <span class="o">=</span> <span class="nf">einsum</span><span class="p">(</span><span class="sh">"</span><span class="s">b h i j, b h d j -&gt; b h i d</span><span class="sh">"</span><span class="p">,</span> <span class="n">attn</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="nf">rearrange</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="sh">"</span><span class="s">b h (x y) d -&gt; b (h d) x y</span><span class="sh">"</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">h</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">out_proj</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</code></pre></div></div> <h4 id="group-normalization">Group Normalization</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">GNorm</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">fn</span> <span class="o">=</span> <span class="n">fn</span>
        <span class="n">self</span><span class="p">.</span><span class="n">groupnorm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">GroupNorm</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">groupnorm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div> <h4 id="utils-blocks">Utils Blocks</h4> <p>Residual</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Residual</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fn</span> <span class="o">=</span> <span class="n">fn</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span>
</code></pre></div></div> <p>Downsample block</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Downsample</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">out_dim</span> <span class="o">=</span> <span class="n">out_dim</span> <span class="k">if</span> <span class="n">out_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">in_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">down_mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="nc">Rearrange</span><span class="p">(</span><span class="sh">"</span><span class="s">b c (h p1) (w p2) -&gt; b (c p1 p2) h w</span><span class="sh">"</span><span class="p">,</span> <span class="n">p1</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">p2</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">in_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">down_mlp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <p>Upsample block</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Upsample</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">out_dim</span> <span class="o">=</span> <span class="n">out_dim</span> <span class="k">if</span> <span class="n">out_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">in_dim</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">up_mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">nearest</span><span class="sh">'</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">up_mlp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <h4 id="the-whole-model">The whole model</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">AttUNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> 
                 <span class="n">init_dim</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> 
                 <span class="n">out_dim</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> 
                 <span class="n">dim_mults</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
                 <span class="n">channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                 <span class="n">self_condition</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                 <span class="n">resnet_block_groups</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">channels</span>
        <span class="n">self</span><span class="p">.</span><span class="n">self_condition</span> <span class="o">=</span> <span class="n">self_condition</span>
        <span class="n">input_channels</span> <span class="o">=</span> <span class="n">channels</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="k">if</span> <span class="n">self_condition</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="n">init_dim</span> <span class="o">=</span> <span class="n">init_dim</span> <span class="k">if</span> <span class="n">init_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">init_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">init_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">init_dim</span><span class="p">,</span> <span class="o">*</span><span class="nf">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">m</span> <span class="p">:</span> <span class="n">dim</span> <span class="o">*</span> <span class="n">m</span><span class="p">,</span> <span class="n">dim_mults</span><span class="p">)]</span>
        <span class="n">in_out</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">dims</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
        
        <span class="n">block_klass</span> <span class="o">=</span> <span class="nf">partial</span><span class="p">(</span><span class="n">ResNetBlock</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">resnet_block_groups</span><span class="p">)</span>
        
        <span class="c1"># positional embedding
</span>        <span class="n">time_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">*</span> <span class="mi">4</span>
        <span class="n">self</span><span class="p">.</span><span class="n">time_mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="nc">SinusodialPositionalEmbeddings</span><span class="p">(</span><span class="n">dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">time_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">GELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">time_dim</span><span class="p">,</span> <span class="n">time_dim</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="c1"># layers
</span>        <span class="n">self</span><span class="p">.</span><span class="n">downs</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">([])</span>
        <span class="n">self</span><span class="p">.</span><span class="n">ups</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">([])</span>
        <span class="n">num_resolutions</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">in_out</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">in_out</span><span class="p">):</span>
            <span class="n">is_last</span> <span class="o">=</span> <span class="n">ind</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="n">num_resolutions</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            
            <span class="n">self</span><span class="p">.</span><span class="n">downs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">([</span>
                    <span class="nf">block_klass</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">time_emb_dim</span><span class="o">=</span><span class="n">time_dim</span><span class="p">),</span>
                    <span class="nf">block_klass</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">time_emb_dim</span><span class="o">=</span><span class="n">time_dim</span><span class="p">),</span>
                    <span class="nc">Residual</span><span class="p">(</span><span class="nc">GNorm</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">in_dim</span><span class="p">))),</span>
                    <span class="nc">Downsample</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">is_last</span> <span class="k">else</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                <span class="p">])</span>
            <span class="p">)</span>
            
        <span class="n">mid_dim</span> <span class="o">=</span> <span class="n">dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">mid_block1</span> <span class="o">=</span> <span class="nf">block_klass</span><span class="p">(</span><span class="n">mid_dim</span><span class="p">,</span> <span class="n">mid_dim</span><span class="p">,</span> <span class="n">time_emb_dim</span><span class="o">=</span><span class="n">time_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">mid_attention</span> <span class="o">=</span> <span class="nc">Residual</span><span class="p">(</span><span class="nc">GNorm</span><span class="p">(</span><span class="n">mid_dim</span><span class="p">,</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">mid_dim</span><span class="p">)))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">mid_block2</span> <span class="o">=</span> <span class="nf">block_klass</span><span class="p">(</span><span class="n">mid_dim</span><span class="p">,</span> <span class="n">mid_dim</span><span class="p">,</span> <span class="n">time_emb_dim</span><span class="o">=</span><span class="n">time_dim</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="nf">reversed</span><span class="p">(</span><span class="n">in_out</span><span class="p">)):</span>
            <span class="n">is_last</span> <span class="o">=</span> <span class="n">ind</span> <span class="o">==</span> <span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">in_out</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            
            <span class="n">self</span><span class="p">.</span><span class="n">ups</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">([</span>
                    <span class="nf">block_klass</span><span class="p">(</span><span class="n">out_dim</span> <span class="o">+</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">time_emb_dim</span><span class="o">=</span><span class="n">time_dim</span><span class="p">),</span>
                    <span class="nf">block_klass</span><span class="p">(</span><span class="n">out_dim</span> <span class="o">+</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">time_emb_dim</span><span class="o">=</span><span class="n">time_dim</span><span class="p">),</span>
                    <span class="nc">Residual</span><span class="p">(</span><span class="nc">GNorm</span><span class="p">(</span><span class="n">out_dim</span><span class="p">,</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">out_dim</span><span class="p">))),</span>
                    <span class="nc">Upsample</span><span class="p">(</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">is_last</span> <span class="k">else</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                <span class="p">])</span>
            <span class="p">)</span>
            
        <span class="n">self</span><span class="p">.</span><span class="n">out_dim</span> <span class="o">=</span> <span class="n">out_dim</span> <span class="k">if</span> <span class="n">out_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">channels</span>
        
        
        <span class="n">self</span><span class="p">.</span><span class="n">final_res_block</span> <span class="o">=</span> <span class="nf">block_klass</span><span class="p">(</span><span class="n">dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">time_emb_dim</span><span class="o">=</span><span class="n">time_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">final_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">timestep</span><span class="p">,</span> <span class="n">x_self_cond</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">self_condition</span><span class="p">:</span>
            <span class="n">x_self_cond</span> <span class="o">=</span> <span class="n">x_self_cond</span> <span class="k">if</span> <span class="n">x_self_cond</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">x_self_cond</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">init_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
        
        <span class="n">t</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">time_mlp</span><span class="p">(</span><span class="n">timestep</span><span class="p">)</span>
        
        <span class="n">h</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">block1</span><span class="p">,</span> <span class="n">block2</span><span class="p">,</span> <span class="n">attn</span><span class="p">,</span> <span class="n">downsample</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">downs</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nf">block1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">h</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            
            <span class="n">x</span> <span class="o">=</span> <span class="nf">block2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nf">attn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">h</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            
            <span class="n">x</span> <span class="o">=</span> <span class="nf">downsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">mid_block1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">mid_attention</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">mid_block2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">block1</span><span class="p">,</span> <span class="n">block2</span><span class="p">,</span> <span class="n">attn</span><span class="p">,</span> <span class="n">upsample</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">ups</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">.</span><span class="nf">pop</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nf">block1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">.</span><span class="nf">pop</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nf">block2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nf">attn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            
            <span class="n">x</span> <span class="o">=</span> <span class="nf">upsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">final_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">final_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div>]]></content><author><name>Quan Tran</name></author><category term="generative-ai"/><category term="computer-vision"/><category term="generative-ai"/><category term="diffuson-models"/><summary type="html"><![CDATA[Update history 20.12.2023: Created 02.01.2024: Update the math formulation 03.01.2024: Update the model backbone 04.01.2024: Update the implementation]]></summary></entry><entry><title type="html">A (very) simple ML workflow for beginners</title><link href="https://tranminhquan.github.io/blog/2023/simple-workflow-ml-project/" rel="alternate" type="text/html" title="A (very) simple ML workflow for beginners"/><published>2023-02-08T11:25:00+00:00</published><updated>2023-02-08T11:25:00+00:00</updated><id>https://tranminhquan.github.io/blog/2023/simple-workflow-ml-project</id><content type="html" xml:base="https://tranminhquan.github.io/blog/2023/simple-workflow-ml-project/"><![CDATA[<h1 id="simple-workflow-of-ml-problem">Simple workflow of ML problem</h1> <p>Below is a very simple workflow in a ML project</p> <p><em>(Please note that in practices, for larger ML project, things are very complicated, not just simple like this!!!)</em></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/simple_mlworkflow/overall_ml_process-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/simple_mlworkflow/overall_ml_process-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/simple_mlworkflow/overall_ml_process-1400.webp"/> <img src="/assets/img/simple_mlworkflow/overall_ml_process.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Each step will include serveral “actions”, for example</p> <ul> <li><strong>Preprocess</strong>: fill NaN data, remove noise data</li> <li><strong>Feature Engineering</strong>: encode text data to numerical data, scale data</li> <li><strong>Modelling</strong>: set up hyper-parameters, build model</li> <li><strong>Training</strong>: split data, train model</li> <li><strong>Predict</strong>: predict the outcome</li> </ul> <p>Each “action” is generalized as a <strong>function</strong>. As a result, let’s say, for each step, we will have corresponding functions</p> <ul> <li><strong>Preprocess</strong>: <code class="language-plaintext highlighter-rouge">fill_na</code>, <code class="language-plaintext highlighter-rouge">remove_noise</code></li> <li><strong>Feature Engineering</strong>: <code class="language-plaintext highlighter-rouge">encode_data</code>, <code class="language-plaintext highlighter-rouge">scale_data</code></li> <li><strong>Modelling</strong>: <code class="language-plaintext highlighter-rouge">setup_params</code>, <code class="language-plaintext highlighter-rouge">build_model</code></li> <li><strong>Training</strong>: <code class="language-plaintext highlighter-rouge">split_data</code>, <code class="language-plaintext highlighter-rouge">train_model</code></li> <li><strong>Predict</strong>: <code class="language-plaintext highlighter-rouge">predict</code></li> </ul> <h1 id="from-experiment-in-notebook">From experiment in notebook</h1> <p>In Google Colab (or, JupyterLab), this is something as below codes</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># preprocess
</span>
<span class="k">def</span> <span class="nf">remove_noise</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
  <span class="k">pass</span>

<span class="k">def</span> <span class="nf">fill_na</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
  <span class="k">pass</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># feature engineering
</span>
<span class="k">def</span> <span class="nf">encode_data</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
  <span class="k">pass</span>

<span class="k">def</span> <span class="nf">scale_data</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
  <span class="k">pass</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># modelling
</span><span class="k">def</span> <span class="nf">setup_params</span><span class="p">():</span>
  <span class="k">pass</span>

<span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
  <span class="k">pass</span>

</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># training
</span>
<span class="k">def</span> <span class="nf">split_data</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
  <span class="k">pass</span>


<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_data</span><span class="p">):</span>
  <span class="k">pass</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># predict
</span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_to_predict</span><span class="p">):</span>
  <span class="k">pass</span>
</code></pre></div></div> <p>Then, you may call above functions to run the experiments</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import libraries
</span><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># load data
</span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">dog_vs_cat.csv</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># preprocess
</span><span class="n">data</span> <span class="o">=</span> <span class="nf">remove_noise</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="nf">fill_na</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># feature engineering
</span><span class="n">data</span> <span class="o">=</span> <span class="nf">encode_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="nf">scale_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># split data
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">split_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># train model
</span>
<span class="c1"># set up
</span><span class="n">params</span> <span class="o">=</span> <span class="nf">setup_params</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="nf">build_model</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

<span class="c1"># train
</span><span class="n">model</span> <span class="o">=</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">train_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</code></pre></div></div> <p>After training, we may use the trained_model to predict an outcome</p> <p>First, we want to test on the “test_data” that we have split</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># validate the test data
</span><span class="n">test_outcomes</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_to_predict</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</code></pre></div></div> <p>Then, we will you data comming from real world to see how the model reacts Note that, this data comming from real world <strong>HAVE NOT BEEN PROCESSED yet</strong>. So we need to use functions in “preprocess” step</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">real_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">real_dogcat_data.csv</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># We have to PREPROCESS this data (as what we have done with training data)
# preprocess
</span><span class="n">real_data</span> <span class="o">=</span> <span class="nf">remove_noise</span><span class="p">(</span><span class="n">real_data</span><span class="p">)</span>
<span class="n">real_data</span> <span class="o">=</span> <span class="nf">fill_na</span><span class="p">(</span><span class="n">real_data</span><span class="p">)</span>

<span class="c1"># feature engineering
</span><span class="n">real_data</span> <span class="o">=</span> <span class="nf">encode_data</span><span class="p">(</span><span class="n">real_data</span><span class="p">)</span>
<span class="n">real_data</span> <span class="o">=</span> <span class="nf">scale_data</span><span class="p">(</span><span class="n">real_data</span><span class="p">)</span>

<span class="c1"># (this is real data, we do not need to split them)
</span></code></pre></div></div> <p>Finally, we use <code class="language-plaintext highlighter-rouge">predict</code> function to see the outcomes</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">outcomes</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">real_data</span><span class="p">)</span>
</code></pre></div></div> <h1 id="to-engineering-in-vscode">To engineering in VSCode</h1> <p>The above steps you may run serveral times, and “tune” to have a “good enough” model. After that, you may wish to <strong>“bring” your model into an application</strong></p> <p>To do this, we have to “engineering” the codes above</p> <p><strong>“Engineering”</strong> process is to arrange the above code in structure. A structure is something like a folder structure in your computer. Technically, we will transform “.ipynb” to “.py” file</p> <p>What to arrange? We arrange the functions</p> <p>How to arrange? There are many ways</p> <ul> <li>the most basic one is to leverage the above ML process, functions in the same steps will be in the same folder</li> <li>another way is to arrange by their functionalities</li> </ul> <p>In the general process, we have these 2 steps:</p> <ul> <li><strong>Preprocess</strong>: <code class="language-plaintext highlighter-rouge">fill_na</code>, <code class="language-plaintext highlighter-rouge">remove_noise</code></li> <li><strong>Feature Engineering</strong>: <code class="language-plaintext highlighter-rouge">encode_data</code>, <code class="language-plaintext highlighter-rouge">scale_data</code></li> </ul> <p>These functions generally handle data, so we can group them into something called <strong>processing</strong></p> <p>Next, we have this step</p> <ul> <li><strong>Modelling</strong>: <code class="language-plaintext highlighter-rouge">setup_params</code>, <code class="language-plaintext highlighter-rouge">build_model</code> These functions are to build the model, so we can group them into <strong>models</strong></li> </ul> <p>Finally, we have 2 final steps:</p> <ul> <li><strong>Training</strong>: <code class="language-plaintext highlighter-rouge">split_data</code>, <code class="language-plaintext highlighter-rouge">train_model</code></li> <li><strong>Predict</strong>: <code class="language-plaintext highlighter-rouge">predict</code></li> </ul> <p>These functions are to support the process of training, testing, spliting data, predicting, so we can group them into <strong>utils</strong></p> <p>As a result, our “structure” will be</p> <ul> <li><strong>processing</strong>: includes preprocess, and feature engineering</li> <li><strong>models</strong>: setup params, build model</li> <li><strong>utils</strong>: training and predict</li> </ul> <p>Each “structure” will have “steps”, these “steps” can be generalized as “.py” files. Each “step” have functions, these functions will be written in the corresponding “.py” files</p> <p>Below is the resulted structure </p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/simple_mlworkflow/ml_sample_structure-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/simple_mlworkflow/ml_sample_structure-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/simple_mlworkflow/ml_sample_structure-1400.webp"/> <img src="/assets/img/simple_mlworkflow/ml_sample_structure.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In the folder <strong>models</strong>, we can be more specific to create two <code class="language-plaintext highlighter-rouge">cls_models.py</code> and <code class="language-plaintext highlighter-rouge">reg_models.py</code> representing “classification models” and “regression models”. (It’s up to you)</p> <p>In the root, we have <code class="language-plaintext highlighter-rouge">main.py</code> as the “entry” file. “Entry” file is something containing “main code” to run. Something like this (the cell in the notebook)</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/simple_mlworkflow/main-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/simple_mlworkflow/main-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/simple_mlworkflow/main-1400.webp"/> <img src="/assets/img/simple_mlworkflow/main.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Here, we start to “bring” the code in the notebook to the corresponding “folder” in the “structure”. As a result, we will have</p> <p>In the <code class="language-plaintext highlighter-rouge">preprocessing</code> &gt; <code class="language-plaintext highlighter-rouge">feature_engineering.py</code></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/simple_mlworkflow/feature_engineering-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/simple_mlworkflow/feature_engineering-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/simple_mlworkflow/feature_engineering-1400.webp"/> <img src="/assets/img/simple_mlworkflow/feature_engineering.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In the <code class="language-plaintext highlighter-rouge">processing</code> &gt; <code class="language-plaintext highlighter-rouge">preprocess.py</code></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/simple_mlworkflow/preprocess-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/simple_mlworkflow/preprocess-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/simple_mlworkflow/preprocess-1400.webp"/> <img src="/assets/img/simple_mlworkflow/preprocess.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In the <code class="language-plaintext highlighter-rouge">models</code> &gt; <code class="language-plaintext highlighter-rouge">params.py</code></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/simple_mlworkflow/params-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/simple_mlworkflow/params-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/simple_mlworkflow/params-1400.webp"/> <img src="/assets/img/simple_mlworkflow/params.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In the <code class="language-plaintext highlighter-rouge">models</code> &gt; <code class="language-plaintext highlighter-rouge">cls_models.py</code></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/simple_mlworkflow/cls_models-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/simple_mlworkflow/cls_models-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/simple_mlworkflow/cls_models-1400.webp"/> <img src="/assets/img/simple_mlworkflow/cls_models.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In the <code class="language-plaintext highlighter-rouge">utils</code> &gt; <code class="language-plaintext highlighter-rouge">split_data.py</code></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/simple_mlworkflow/split_data-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/simple_mlworkflow/split_data-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/simple_mlworkflow/split_data-1400.webp"/> <img src="/assets/img/simple_mlworkflow/split_data.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In the <code class="language-plaintext highlighter-rouge">utils</code> &gt; <code class="language-plaintext highlighter-rouge">training.py</code></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/simple_mlworkflow/training-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/simple_mlworkflow/training-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/simple_mlworkflow/training-1400.webp"/> <img src="/assets/img/simple_mlworkflow/training.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In the <code class="language-plaintext highlighter-rouge">utils</code> &gt; <code class="language-plaintext highlighter-rouge">predicting.py</code></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/simple_mlworkflow/predicting-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/simple_mlworkflow/predicting-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/simple_mlworkflow/predicting-1400.webp"/> <img src="/assets/img/simple_mlworkflow/predicting.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In the <code class="language-plaintext highlighter-rouge">main.py</code>, we have</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/simple_mlworkflow/final_main-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/simple_mlworkflow/final_main-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/simple_mlworkflow/final_main-1400.webp"/> <img src="/assets/img/simple_mlworkflow/final_main.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Different to notebook which all functions are in the same notebook, functions in engineering are seperated in many “.py” files, so we need to <strong>import</strong> them</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/simple_mlworkflow/import-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/simple_mlworkflow/import-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/simple_mlworkflow/import-1400.webp"/> <img src="/assets/img/simple_mlworkflow/import.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="wrap-up">Wrap up</h1> <p>A simple workflow of ML process </p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/simple_mlworkflow/overall_ml_process-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/simple_mlworkflow/overall_ml_process-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/simple_mlworkflow/overall_ml_process-1400.webp"/> <img src="/assets/img/simple_mlworkflow/overall_ml_process.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Experiment in notebook</p> <ul> <li>Each “step” includes many “actions”</li> <li>These “actions” are generalized as “functions”</li> <li>In notebook, all functions are in the same notebook (.ipynb files)</li> </ul> <p>Engineering in VSCode</p> <ul> <li>Convert notebook “.ipynb” into many “.py” files in a structure</li> <li>A structure has “folders” are group of “steps”</li> <li>Each “step” is a “.py” files</li> <li>Each “.py” file contains many “functions”</li> <li>Bring the “functions” in notebook into corresponding “.py” files</li> <li>A structure has “main.py” file as the “entry” file</li> <li>In the entry file, we can not directly call the functions, we need to “import” them from “.py” files in the structure</li> </ul> <h1 id="demo">Demo</h1> <p>The repo can be found <a href="https://github.com/tranminhquan/simple-ml-template">here</a></p>]]></content><author><name></name></author><category term="engineering"/><category term="fundamentals"/><category term="inanutshell"/><category term="workflow"/><summary type="html"><![CDATA[Simple workflow of ML problem Below is a very simple workflow in a ML project]]></summary></entry><entry><title type="html">Beginner to git? This post is for you</title><link href="https://tranminhquan.github.io/blog/2023/git-commands/" rel="alternate" type="text/html" title="Beginner to git? This post is for you"/><published>2023-01-27T11:25:00+00:00</published><updated>2023-01-27T11:25:00+00:00</updated><id>https://tranminhquan.github.io/blog/2023/git-commands</id><content type="html" xml:base="https://tranminhquan.github.io/blog/2023/git-commands/"><![CDATA[<h1 id="why-git">Why git?</h1> <p>Have you ever modify on a same file, say, Google docs, with your college? It may have conflicts when all of you modify in the same line. Yes, that’s where git comes to rescue</p> <p>Each time you and your colleges modify the file, the new version is created, we need to control it. Yes, that’s where git comes to rescue</p> <p>-&gt; Git is a solution for version control</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/git_commands/overview_git_1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/git_commands/overview_git_1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/git_commands/overview_git_1-1400.webp"/> <img src="/assets/img/git_commands/overview_git_1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ul> <li>Dot represents the file at that time</li> <li> <p>Line connecting the dots represents the worflow of the file</p> </li> <li><strong>Line of GREEN dots</strong> is the “main” workflow</li> <li><strong>Line of BLUE dots</strong> is “your” workflow: when you modify the “main” workflow, you just <strong>PULL</strong> the “main” workflow to create your own workflow</li> <li> <p><strong>Line of ORANGE dots</strong> is “your college” workflow: same as you when he or she modify the “main”, he or she may <strong>PULL</strong> the “main” workflow to create his or her workflow</p> </li> <li>After completing modifcation, <strong>you MERGE</strong> it to the “main” workflow (BLUE line merges to GREEN line)</li> <li>After completing modification, <strong>your college MERGES</strong> it to the “main” workflow (ORANGE line merges to GREEN line)</li> <li>At the “main” worflow (GREEN line), it will be automatically aggregated from “your” and “your college” workflow</li> </ul> <p>That’s how GIT work</p> <p>So, where is the “main” workflow? It comes from a shared place specifically for code (just something like Google Drive or One Drive). Some popular services are Github, Gitlab</p> <p>Where is “your” worflow? It’s on your personal computer. The same for “your college” worflow. It’s on his or her computer.</p> <p>You can see that the above process requires two things: <strong>PULL</strong> and <strong>MERGE</strong></p> <ul> <li><strong>PULL</strong>: get the file from “main” worflow to your computer</li> <li><strong>MERGE</strong>: contains 2 steps: <strong>PUSH</strong> the file on your computer to the shared place (“main” workflow), and, <strong>MERGE</strong> means updating the “main” file. (Because you have modified the file, it needs to be merged to the current “main” file)</li> </ul> <p>Below is the demonstration of a simple file</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/git_commands/overview_git_2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/git_commands/overview_git_2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/git_commands/overview_git_2-1400.webp"/> <img src="/assets/img/git_commands/overview_git_2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In summary, we have 2 sides: the shared place and the workplace on your computer</p> <ul> <li>The shared place is called <strong>REMOTE</strong></li> <li>The workplace of yours is called <strong>LOCAL</strong></li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/git_commands/git_commands-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/git_commands/git_commands-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/git_commands/git_commands-1400.webp"/> <img src="/assets/img/git_commands/git_commands.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In the <strong>LOCAL</strong>, it is divided into 3 states:</p> <ul> <li>Working directory: where you are coding (e.g. VSCode), this place will NOT AFFECT the change of “your work”</li> <li>Staging: a “temperory” place to “index” the change of your working directory. This place will AFFECT the change of “your work”</li> <li>Local repository: your “workplace”, you will <strong>PUSH</strong> your work from here to the <strong>REMOTE</strong></li> </ul> <p>The <strong>REMOTE</strong> is the shared place, it can be placed on any familiar platform, two popular ones are <em>Github</em> and <em>Gitlab</em>. Its official name is <strong>repository</strong>, or (<strong>repo</strong> in short)</p> <p>Now supose your <strong>repo</strong> already existed and you are assigned to work together with your team on it.</p> <ul> <li>To “get” the code from <strong>repo</strong> to the <strong>local</strong>, use <strong>git pull</strong> command</li> <li>Then, you will modify the code on the Working directory, when you finish, you need to “update” it to the <strong>repo</strong> by $3$ steps: <ul> <li>Add <em>what changes you want</em> to the staging using <strong>git add</strong> command</li> <li>Move it to the <strong>local</strong> and ready for the <strong>repo&amp;&amp; by using **git commit</strong> command</li> <li>Officially push to the <strong>repo</strong> by using <strong>git push</strong> command</li> </ul> </li> </ul> <h1 id="summary">Summary</h1> <ul> <li> <p><strong>Repo</strong> is the <strong>remote</strong> place to storing code on. Some popular providers are <em>Github</em>, <em>Gitlab</em></p> </li> <li> <p><strong>Local</strong> is your workplace on your computer</p> </li> <li><strong>git pull</strong>: get the code from <strong>repo</strong> to <strong>local</strong></li> <li><strong>git add</strong>: add <em>changes</em> from what you have modified to the staging</li> <li><strong>git commit</strong>: confirm those <em>changes</em> that be ready to share on repo</li> <li><strong>git push</strong>: officially push tose <em>changes</em> to the <strong>repo</strong></li> </ul> <h1 id="git-in-practice">Git in practice</h1> <ul> <li>Initialize the repo from existing work</li> <li>Communicate with git when working</li> </ul> <h2 id="initialize-the-repo-from-existing-work">Initialize the repo from existing work</h2> <p>Suppose you have an existing work, and want to intialize a shared place on Github </p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/git_commands/existing_work-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/git_commands/existing_work-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/git_commands/existing_work-1400.webp"/> <img src="/assets/img/git_commands/existing_work.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In the termnial,</p> <ul> <li>Initialize git by using <strong>git init</strong> commands. This will setup a local <strong>repository</strong> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/git_commands/git_init-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/git_commands/git_init-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/git_commands/git_init-1400.webp"/> <img src="/assets/img/git_commands/git_init.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ul> <li> <p>Add <em>changes</em> you want by using <strong>git add</strong> <em>&lt;files or folders&gt;</em>. If you want to add *all changes<strong>, simply use **git add .</strong></p> <ul> <li>Option 1: If you want to add, e.g. these files, add these path using <strong>git add</strong>, you can verify the added changes by using <strong>git status</strong>, which are in green</li> </ul> <p></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/git_commands/git_add_files-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/git_commands/git_add_files-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/git_commands/git_add_files-1400.webp"/> <img src="/assets/img/git_commands/git_add_files.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </li> </ul> <p>&lt;/figure&gt;</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;!-- ![git_add_files_2](/assets/img/git_commands/git_add_files_2.png) --&gt;
&lt;figure&gt;
</code></pre></div></div> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/git_commands/git_add_files_2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/git_commands/git_add_files_2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/git_commands/git_add_files_2-1400.webp"/> <img src="/assets/img/git_commands/git_add_files_2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <p>&lt;/figure&gt;</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;!-- ![git_add_files_3](/assets/img/git_commands/git_add_files_3.png) --&gt;
&lt;figure&gt;
</code></pre></div></div> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/git_commands/git_add_files_3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/git_commands/git_add_files_3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/git_commands/git_add_files_3-1400.webp"/> <img src="/assets/img/git_commands/git_add_files_3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <p>&lt;/figure&gt;</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* Option 2: If you want to add all files, use **git add .**, then use **git status** to verify, all files are in green

&lt;!-- ![git_add_all](/assets/img/git_commands/git_add_all.png) --&gt;
&lt;figure&gt;
</code></pre></div></div> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/git_commands/git_add_all-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/git_commands/git_add_all-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/git_commands/git_add_all-1400.webp"/> <img src="/assets/img/git_commands/git_add_all.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <p>&lt;/figure&gt;</p> <ul> <li> <p>To confirm those <em>changes</em> will be push to <strong>remote repo</strong>, use commands <strong>git commit -m</strong> <em>&lt;your note or comments&gt;</em></p> <p></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/git_commands/git_commit_fail-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/git_commands/git_commit_fail-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/git_commands/git_commit_fail-1400.webp"/> <img src="/assets/img/git_commands/git_commit_fail.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </li> </ul> <p>&lt;/figure&gt;</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>If the above error occurs, that means you haven't clarify yourself, then add your user name and email by using those commands. Note that only add the "--global" if you are using your personal device, if you are on a shared server, it is better to remove it.

&lt;!-- ![git_config_identification](/assets/img/git_commands/git_config_identification.png) --&gt;
&lt;figure&gt;
</code></pre></div></div> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/git_commands/git_config_identification-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/git_commands/git_config_identification-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/git_commands/git_config_identification-1400.webp"/> <img src="/assets/img/git_commands/git_config_identification.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <p>&lt;/figure&gt;</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Then, use **git commit** again. Git will tell you all files are confirmed

&lt;!-- ![git_commit](/assets/img/git_commands/git_commit.png) --&gt;
&lt;figure&gt;
</code></pre></div></div> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/git_commands/git_commit-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/git_commands/git_commit-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/git_commands/git_commit-1400.webp"/> <img src="/assets/img/git_commands/git_commit.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <p>&lt;/figure&gt;</p> <ul> <li> <p>To officially push those <em>changes</em> to <strong>remote repo</strong>, you <strong>git push</strong>. However, you do not have a <strong>remote repo</strong> at this time. So, first, create a <strong>repo</strong> on Github</p> <p></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/git_commands/create_repo-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/git_commands/create_repo-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/git_commands/create_repo-1400.webp"/> <img src="/assets/img/git_commands/create_repo.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </li> </ul> <p>&lt;/figure&gt;</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>You will see a https url of your repo, copy it. Back to the terminal, use **git remote add origin** */&lt; https url /&gt;* to connect with the above repo

&lt;!-- ![git_remote_add](/assets/img/git_commands/git_remote_add.png) --&gt;
&lt;figure&gt;
</code></pre></div></div> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/git_commands/git_remote_add-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/git_commands/git_remote_add-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/git_commands/git_remote_add-1400.webp"/> <img src="/assets/img/git_commands/git_remote_add.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <p>&lt;/figure&gt;</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Officially push to the remote repo by using **git push -u origin master**
&lt;!-- ![git_push](/assets/img/git_commands/git_push.png) --&gt;
&lt;figure&gt;
</code></pre></div></div> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/git_commands/git_push-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/git_commands/git_push-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/git_commands/git_push-1400.webp"/> <img src="/assets/img/git_commands/git_push.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <p>&lt;/figure&gt;</p>]]></content><author><name></name></author><category term="engineering"/><category term="fundamentals"/><category term="inanutshell"/><category term="git"/><summary type="html"><![CDATA[Why git? Have you ever modify on a same file, say, Google docs, with your college? It may have conflicts when all of you modify in the same line. Yes, that’s where git comes to rescue]]></summary></entry><entry><title type="html">Bayesian Optimization</title><link href="https://tranminhquan.github.io/blog/2021/bayesia-opt/" rel="alternate" type="text/html" title="Bayesian Optimization"/><published>2021-01-30T00:00:00+00:00</published><updated>2021-01-30T00:00:00+00:00</updated><id>https://tranminhquan.github.io/blog/2021/bayesia-opt</id><content type="html" xml:base="https://tranminhquan.github.io/blog/2021/bayesia-opt/"><![CDATA[<h1 id="opening-discussion">Opening Discussion</h1> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bayesian_opt/open_discussion-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bayesian_opt/open_discussion-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bayesian_opt/open_discussion-1400.webp"/> <img src="/assets/img/bayesian_opt/open_discussion.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="levels-of-optimization-problem-solving">Levels of Optimization Problem Solving</h1> <p>In general, we can divided the way to solve optmization problem into \(3\) levels:</p> <ul> <li><strong>Level 0</strong>: Non-derivative, including some familiar approaches such as: Grid Search, Random Search, Bayesian Optimization, etc. <ul> <li>Pros: Fast computation, do not require the function to be smooth, i.e. no differentiable required, the function need continous</li> <li>Cons: It is heuristic, not a theory-based method</li> </ul> </li> <li><strong>Level 1</strong>: First-derivative. \(∇f(x) = f(x_i)_i\). The most popular one is Gradient Descent (Adam, Nesterov, etc.) <ul> <li>Pros: Efficient to converge in local minimum/maximum</li> <li>Cons: Computational since it requires backpropagation</li> </ul> </li> <li><strong>Level 2</strong>: Second-derivatie. \(J(f) = f(x_i, x_j)_{ij}\) (i.e. Newton) <ul> <li>Pros: Very effective, faster convergence than level-1 method</li> <li>Cons: Significantly compuational</li> </ul> </li> </ul> <p>Bayesian Optimization is the one in level 0</p> <h1 id="bayesian-optimization">Bayesian Optimization</h1> <h2 id="when-to-use-bayesian-optimization">When to use Bayesian Optimization</h2> <p>Supose that we are optimzing a function \(f(x, \Theta)\) \(\max_{\Theta}f(x,\Theta)\)</p> <p>We can consider Bayesian Optimzation if $f$ satisfy following conditions:</p> <ul> <li>$f$ has to be continuous</li> <li>$f$ is expensive to evaluate</li> <li>$f$ is a blackbox. In other words, we don’t know characteristic of $f$ (convex, non-convex, derivative, etc.)</li> </ul> <h2 id="fundementals-of-bayesian-optmization">Fundementals of Bayesian Optmization</h2> <p>Instead of directly optimizing $f$, we approximate it by other easier evaluation function \(P\), and define a strategy $u$ to optimize \(P\)</p> <ul> <li>\(P\) - <strong>Surrogate model</strong>: <ul> <li>the alternative of \(f\), easier to optmize</li> <li>Gaussian Process, etc.</li> </ul> </li> <li>\(u\) - <strong>Acquisition function</strong>: <ul> <li>strategy to optmize surrogate model</li> <li>Expected Improvement (EI), Upper Condidence Bound (UCB), etc.</li> </ul> </li> </ul> <p>In this article, we focus on the most popular surrogate model - the Gaussian Process</p> <h2 id="gaussian-process">Gaussian Process</h2> <p>As mentioned, \(f\) is black box and expensive to evaluate. Hence, the surrogate model should be an alternative that is easier to evaluate. A good intuition is to approximate \(f\) as a distribution (normally Gaussian Distribution).<br/> In other words, we consider \(f\) as a Gaussian Distribution with mean \(\mu(x)\) and standard deviation \(\sigma^2(x)\)</p> \[f(x) \sim \mathcal{N}(\mu(x), \sigma^2(x))\] <p>Hence, the Gaussian Process \(P\) has the Probability Density Function (PDF) as</p> \[P(f(x)=y) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp{\frac{|y - \mu(x)|^2}{2\sigma^2}}\] <p>The figure below demonstrates it as a distribution approximation </p> <p>Therefore, Gaussian Process makes use of Bayes Theory. Since we literally has no information about how \(f\) looks like (<em>the solid red line</em>), we just has some initial observations (<em>blue circle</em>). <strong>The surrogate model gives us a probabilistic estimation of $f$ as a distribution (<em>the area limited by dash red line</em>)</strong></p> <p>From this, we need to select the next point (i.e. \(x_+\)) to sample from \(f\). The strategy to select the next point from the observation of surrogate model is taken by <strong>acquisition function</strong>.</p> <p>After the next point is sampled, i.e. \(\{x_+, y=f(x_+)\}\). We continue to fit it as prior knowledge to surrogate model and continue to select next point, i.e. \(x_{++}\). Gradually, we will have a more knowledge on how \(f\) looks like as the belief keeps increasing.</p> <h2 id="acquisition-function">Acquisition function</h2> <p>The strategy that proposes the next sampling point is decided by acquisition function \(u\). Particularly, we optimize \(u\) over surrogate model \(P\). Note that as mentioned, those functions are easier to optimize comparing to \(f\)<br/> There are lots of <strong>acquisition function</strong>, the most popular ones are <strong>Expected Improvement</strong> \(EI\), and <strong>Upper Confidence Bound</strong> \(UCB\). In this article, we define \(EI\) as the acquisition function.</p> <p>Expected Improvement function is defined as \(EI(x) = \mathbb{E} \max (x - f(x^*))\)</p> <p>The intuition is that the chosen next sampling point should have maximal expected values comparing the best of those from observations. The best point from existing observations is denoted as \(x^* = \arg\max_{x_i \in D} f(x_i)\)</p> <p>Since we are optimizing acquisition function over a Gaussian Process, the more particular formula can be clarified as \(EI(x) = \begin{cases} \displaystyle (\mu(x) - f(x^*) - \xi)\varphi(Z) + \sigma(x)\phi(Z) &amp; \text{if} &amp; \sigma(x) &gt; 0 \\ \displaystyle 0 &amp; \text{if} &amp; \sigma(x) = 0 \end{cases}\)</p> <p>where</p> \[Z = \begin{cases} \displaystyle \frac{\mu(x) - f(x^*) - \xi}{\sigma(x)} &amp; \text{if} &amp; \sigma(x) &gt; 0 \\ \displaystyle 0 &amp; \text{if} &amp; \sigma(x) = 0 \end{cases}\] <p>The adjusted parameter \(\xi\) is use to balance between <em>exploitation</em> and <em>exploration</em> of two summation terms in the above equation, respectively.</p> <p>High \(\xi\) means we lower the probability of first term (the one calculating with mean \(\mu\), i.e. the certainty), hence, increase the probability of second term (the one calculating with variance \(\sigma\), i.e. the uncertainty) –&gt; we want to explore on the area of uncertainty more, and vice versa.</p> <h2 id="the-complete-process">The complete process</h2> <p>In summary, the overall process of Bayesian Optimization can be clarified as follows: We want to find the optimal values of objective function \(f\) with <strong>surrogate model</strong> \(P\) and <strong>acquisition function</strong> \(u\). Initially, we have limited observations \(D={x_N, y_N}\). The iteration below is how Bayesian Optimization works:<br/> — <br/> 1. Fit \({x_N, y_N}\) to approximate surrogate model \(P\)<br/> 2. Optimize acquisition function \(u\) over \(P\) to sample the next point \(x_{N+} = u(x)\)<br/> 3. Evaluate \(\{x_{N+}\}\) on \(f\) to get \(y_{N+}\)<br/> 4. Add \(\{x_{N+}, y_{N+}\}\) to D and repeat the process</p> <p>The detail about implementation from scratch can be found at <a href="http://krasserm.github.io/2018/03/19/gaussian-processes/">[4]</a></p> <p>Below is the demonstration step-by-step:</p> <p>Suppose we want to find the values that maximize the objective function below (which is unknown) with some initial observations. </p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bayesian_opt/process_step1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bayesian_opt/process_step1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bayesian_opt/process_step1-1400.webp"/> <img src="/assets/img/bayesian_opt/process_step1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ol> <li>Approximate a surrogate model \(P\) (i.e. Gaussian Process). The green area is CI - Confidence Interval drawn from \(\sigma^2\) of surrogate model, depicts the uncertainty over objective function </li> </ol> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bayesian_opt/process_step2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bayesian_opt/process_step2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bayesian_opt/process_step2-1400.webp"/> <img src="/assets/img/bayesian_opt/process_step2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ol> <li>Apply acquisition function \(u\) over \(P\). As a result, it proposed the next sampling point as blue circle </li> </ol> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bayesian_opt/process_step3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bayesian_opt/process_step3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bayesian_opt/process_step3-1400.webp"/> <img src="/assets/img/bayesian_opt/process_step3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ol> <li>Evaluate the proposed sampling point using objective function. We can observe that the uncertainty significantly narrow down. We repeat this process through a number of iterations </li> </ol> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bayesian_opt/process_step4-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bayesian_opt/process_step4-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bayesian_opt/process_step4-1400.webp"/> <img src="/assets/img/bayesian_opt/process_step4.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="discussion">Discussion:</h2> <p>We may have a general observation about Bayesian Optimization. However, there are still some that we have resolve yet:</p> <ul> <li>Alternatively, we optimize acquisition function over surrogate model instead of objective function since it cheaper, yet it is not clear the approach to optimize acquisition function</li> <li>Beside Expected Improvement, other popular acquisition functions are UCB, Probability of Improvement</li> </ul> <h1 id="implementation">Implementation</h1> <p>To simplify the implementation, we suppose that:</p> <ul> <li>We have already known the objective function for the verification.</li> <li>The surrogate model makes use of Gaussian Process Regression provided by <code class="language-plaintext highlighter-rouge">scikit-learn</code></li> <li>The process of optimizing the acquisition function will be handled by <code class="language-plaintext highlighter-rouge">scipy</code> employing <em>Broyden–Fletcher–Goldfarb–Shanno</em> algorithm[6]</li> </ul> <p>We will implement</p> <ul> <li>The Bayesian Optimization process</li> <li>A method maximizing acquisition function</li> <li>An instance of acquisition function, i.e. Expected Improvement</li> </ul> <h2 id="set-up">Set up</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># TO-DO: problem with scipy &gt; 1.4, find out solution
</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">unistall</span> <span class="n">scipy</span> <span class="o">--</span><span class="n">y</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">scipy</span><span class="o">==</span><span class="mf">1.4</span><span class="p">.</span><span class="mi">1</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># assume the objective function f
</span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="mi">6</span><span class="o">*</span><span class="n">X</span><span class="p">)</span> <span class="o">-</span> <span class="n">X</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">0.05</span><span class="o">*</span><span class="n">X</span> <span class="o">+</span> <span class="n">noise</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Initial samples
</span><span class="n">noise</span><span class="o">=</span><span class="mf">0.2</span>
<span class="n">X_inits</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.9</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.1</span><span class="p">]])</span>
<span class="n">y_inits</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">X_inits</span><span class="p">,</span> <span class="n">noise</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">X_inits</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_inits</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Bounds of x
</span><span class="n">bounds</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">]])</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(2, 1) (2, 1)
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># enrich samples to draw objective function
</span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">bounds</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">bounds</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="mf">0.01</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">noise</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">The objective function and initial observations: </span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="sh">'</span><span class="s">y--</span><span class="sh">'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Objective function</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nf">f</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">noise</span><span class="p">),</span> <span class="sh">'</span><span class="s">gx</span><span class="sh">'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Noisy samples</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X_inits</span><span class="p">,</span> <span class="n">y_inits</span><span class="p">,</span> <span class="sh">'</span><span class="s">kx</span><span class="sh">'</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Initial samples</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The objective function and initial observations: 
</code></pre></div></div> <h2 id="bayesian-optimization-1">Bayesian Optimization</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># !wget !wget https://raw.githubusercontent.com/krasserm/bayesian-machine-learning/dev/bayesian-optimization/bayesian_optimization_util.py
</span></code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.gaussian_process</span> <span class="kn">import</span> <span class="n">GaussianProcessRegressor</span>
<span class="kn">from</span> <span class="n">sklearn.gaussian_process.kernels</span> <span class="kn">import</span> <span class="n">ConstantKernel</span><span class="p">,</span> <span class="n">Matern</span>
<span class="kn">from</span> <span class="n">bayesian_optimization_util</span> <span class="kn">import</span> <span class="n">plot_approximation</span><span class="p">,</span> <span class="n">plot_acquisition</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">process_bayesian_opt</span><span class="p">(</span><span class="n">X_samples</span><span class="p">,</span> <span class="n">y_samples</span><span class="p">,</span> <span class="n">gpr</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Single iteration of a Bayeisan Optimization process
    Args:
        X_samples: 
        y_samples: 
        gpr: 
        
    Returns:
        Next sampling pair {X, y}
    </span><span class="sh">"""</span>
    
    <span class="c1"># approximate GPR
</span>    <span class="n">gpr</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_samples</span><span class="p">,</span> <span class="n">y_samples</span><span class="p">)</span>

    <span class="c1"># optimize acquisition over GPR to chose next sampling point X_next
</span>    <span class="n">X_next</span> <span class="o">=</span> <span class="nf">optimize_acquisition</span><span class="p">(</span><span class="n">EI</span><span class="p">,</span> <span class="n">X_samples</span><span class="p">,</span> <span class="n">y_samples</span><span class="p">,</span> <span class="n">gpr</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">n_restarts</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>

    <span class="c1"># evaluate to get y_next
</span>    <span class="n">y_next</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">X_next</span><span class="p">,</span> <span class="n">noise</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">X_next</span><span class="p">,</span> <span class="n">y_next</span>
</code></pre></div></div> <h2 id="optimize-acquisition">Optimize acquisition</h2> <p><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html"><code class="language-plaintext highlighter-rouge">scipy.optimize.minimize</code></a></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>

<span class="k">def</span> <span class="nf">optimize_acquisition</span><span class="p">(</span><span class="n">acquisition_func</span><span class="p">,</span> <span class="n">X_sample</span><span class="p">,</span> <span class="n">y_sample</span><span class="p">,</span> <span class="n">gpr</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">n_restarts</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Optimize acquisition function
    Args:
        acquisition_func: 
        X_sample: 
        y_sample: 
        gpr: 
        bounds:
        n_restarts:
        
    Returns:
        proposed location
    </span><span class="sh">"""</span>
    
    <span class="n">dim</span> <span class="o">=</span> <span class="n">X_sample</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">min_value</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">min_x</span> <span class="o">=</span> <span class="bp">None</span>
    
    <span class="k">def</span> <span class="nf">minimize_objective</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="o">-</span><span class="nf">acquisition_func</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">dim</span><span class="p">),</span> <span class="n">X_sample</span><span class="p">,</span> <span class="n">y_sample</span><span class="p">,</span> <span class="n">gpr</span><span class="p">)</span>
    
    <span class="c1"># minimize by a popular algorithm
</span>    <span class="k">for</span> <span class="n">x0</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="n">bounds</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">bounds</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_restarts</span><span class="p">,</span> <span class="n">dim</span><span class="p">)):</span>
        <span class="n">min_ei</span> <span class="o">=</span> <span class="nf">minimize</span><span class="p">(</span><span class="n">minimize_objective</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="sh">'</span><span class="s">L-BFGS-B</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">min_ei</span><span class="p">.</span><span class="n">fun</span> <span class="o">&lt;</span> <span class="n">min_value</span><span class="p">:</span>
            <span class="n">min_value</span> <span class="o">=</span> <span class="n">min_ei</span><span class="p">.</span><span class="n">fun</span>
            <span class="n">min_x</span> <span class="o">=</span> <span class="n">min_ei</span><span class="p">.</span><span class="n">x</span>
    
    <span class="k">return</span> <span class="n">min_x</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <h2 id="acquisition_func-expected-improvement"><code class="language-plaintext highlighter-rouge">acquisition_func</code>: Expected Improvement</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>

<span class="k">def</span> <span class="nf">EI</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X_sample</span><span class="p">,</span> <span class="n">y_sample</span><span class="p">,</span> <span class="n">gpr</span><span class="p">,</span> <span class="n">xi</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Expected Improvement acquisition function
    Args:
        X
        X_sample: 
        y_sample: 
        gpr:
        xi: 
    
    Returns
        EI at X
    </span><span class="sh">"""</span>
    
    <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">gpr</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">mu_sample</span> <span class="o">=</span> <span class="n">gpr</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_sample</span><span class="p">)</span>
    
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># find f(x^*)
</span>    <span class="n">mu_max</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">mu_sample</span><span class="p">)</span>
    
    <span class="c1"># EI formula
</span>    <span class="k">with</span> <span class="n">np</span><span class="p">.</span><span class="nf">errstate</span><span class="p">(</span><span class="n">divide</span><span class="o">=</span><span class="sh">'</span><span class="s">warn</span><span class="sh">'</span><span class="p">):</span>
        <span class="n">mu_dst</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">-</span> <span class="n">mu_max</span> <span class="o">-</span> <span class="n">xi</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="n">mu_dst</span> <span class="o">/</span> <span class="n">sigma</span>
        <span class="n">ei</span> <span class="o">=</span> <span class="n">mu_dst</span> <span class="o">*</span> <span class="n">norm</span><span class="p">.</span><span class="nf">cdf</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span> <span class="o">+</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">norm</span><span class="p">.</span><span class="nf">pdf</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
        <span class="n">ei</span><span class="p">[</span><span class="n">sigma</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>
    
    <span class="k">return</span> <span class="n">ei</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">m52</span> <span class="o">=</span> <span class="nc">ConstantKernel</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="nc">Matern</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span>
<span class="n">gpr</span> <span class="o">=</span> <span class="nc">GaussianProcessRegressor</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">m52</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">noise</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">n_iters</span> <span class="o">=</span> <span class="mi">12</span>

<span class="n">X_samples</span> <span class="o">=</span> <span class="n">X_inits</span>
<span class="n">y_samples</span> <span class="o">=</span> <span class="n">y_inits</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">*</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_iters</span><span class="p">):</span>    
    <span class="n">X_next</span><span class="p">,</span> <span class="n">y_next</span> <span class="o">=</span> <span class="nf">process_bayesian_opt</span><span class="p">(</span><span class="n">X_samples</span><span class="p">,</span> <span class="n">y_samples</span><span class="p">,</span> <span class="n">gpr</span><span class="p">)</span>
    
    <span class="c1"># Plot samples, surrogate function, noise-free objective and next sampling location
</span>    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="n">n_iters</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="nf">plot_approximation</span><span class="p">(</span><span class="n">gpr</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_samples</span><span class="p">,</span> <span class="n">y_samples</span><span class="p">,</span> <span class="n">X_next</span><span class="p">,</span> <span class="n">show_legend</span><span class="o">=</span><span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Iteration </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="n">n_iters</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
    <span class="nf">plot_acquisition</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nc">EI</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X_samples</span><span class="p">,</span> <span class="n">y_samples</span><span class="p">,</span> <span class="n">gpr</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">X_next</span><span class="p">,</span> <span class="n">show_legend</span><span class="o">=</span><span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Add sample to previous samples
</span>    <span class="n">X_samples</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">((</span><span class="n">X_samples</span><span class="p">,</span> <span class="n">X_next</span><span class="p">))</span>
    <span class="n">y_samples</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">((</span><span class="n">y_samples</span><span class="p">,</span> <span class="n">y_next</span><span class="p">))</span>

</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">bayesian_optimization_util</span> <span class="kn">import</span> <span class="n">plot_convergence</span>

<span class="nf">plot_convergence</span><span class="p">(</span><span class="n">X_sample</span><span class="p">,</span> <span class="n">Y_sample</span><span class="p">)</span>
</code></pre></div></div> <h1 id="references">References</h1> <p>[1] A Tutorial on Bayesian Optimization: https://arxiv.org/pdf/1807.02811.pdf<br/> [2] <a href="https://towardsdatascience.com/the-intuitions-behind-bayesian-optimization-with-gaussian-processes-7e00fcc898a0">The intuitions behind Bayesian Optimization with Gaussian Processes</a><br/> [3] <a href="https://orbi.uliege.be/bitstream/2268/226433/1/PyData%202017_%20Bayesian%20optimization%20with%20Scikit-Optimize.pdf">Bayesian optimization with Scikit-Optimize</a><br/> [4] <a href="http://krasserm.github.io/2018/03/21/bayesian-optimization/">Bayesian Optimization</a><br/> [5] <a href="http://krasserm.github.io/2018/03/19/gaussian-processes/">Gaussian processes</a><br/> [6] <a href="https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm">Broyden–Fletcher–Goldfarb–Shanno algorithm</a></p>]]></content><author><name>Quan Tran</name></author><category term="probabilistic-ml"/><category term="paramsearch"/><category term="bayes"/><category term="probml"/><summary type="html"><![CDATA[Opening Discussion]]></summary></entry><entry><title type="html">How to set up a basic GPU environment on Google Cloud Platform</title><link href="https://tranminhquan.github.io/blog/2019/how-to-set-up-a-basic-gpu-environment-on-google-cloud-platform/" rel="alternate" type="text/html" title="How to set up a basic GPU environment on Google Cloud Platform"/><published>2019-02-17T14:31:00+00:00</published><updated>2019-02-17T14:31:00+00:00</updated><id>https://tranminhquan.github.io/blog/2019/how-to-set-up-a-basic-gpu-environment-on-google-cloud-platform</id><content type="html" xml:base="https://tranminhquan.github.io/blog/2019/how-to-set-up-a-basic-gpu-environment-on-google-cloud-platform/"><![CDATA[]]></content><author><name></name></author></entry></feed>